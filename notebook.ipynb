{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch_geometric import data\n",
    "import numpy as np\n",
    "\n",
    "from awe import utils, filtering, features, html_utils, awe_graph\n",
    "from awe.data import swde, live, dataset\n",
    "from awe.features import extraction\n",
    "\n",
    "for module in [utils, filtering, dataset, swde, live, extraction, html_utils, awe_graph]:\n",
    "    importlib.reload(module)\n",
    "utils.reload('awe.features', 'awe.visual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_VALIDITY = False\n",
    "sds = swde.Dataset(suffix='-exact')\n",
    "invalid_pages = [] if not CHECK_VALIDITY else sds.validate(\n",
    "    parallelize=16,\n",
    "    skip=0,\n",
    "    verticals=sds.verticals[:1],\n",
    "    collect_errors=True,\n",
    "    #error_callback=lambda i, _, e: print(f'{i}: {str(e)}'),\n",
    "    save_list=True,\n",
    "    read_list=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.summarize_pages(p for _, p, _ in invalid_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = slice(None)\n",
    "websites = sds.verticals[0].websites\n",
    "rng = np.random.default_rng(42)\n",
    "website_indices = rng.choice(len(websites), 5, replace=False)\n",
    "train_pages = [\n",
    "    p for i in website_indices\n",
    "    for p in websites[i].pages\n",
    "]\n",
    "val_pages = [\n",
    "    p for i in range(len(websites))\n",
    "    if i not in website_indices\n",
    "    for p in rng.choice(websites[i].pages, 50, replace=False)\n",
    "]\n",
    "ds = dataset.DatasetCollection()\n",
    "ds.create('train', train_pages[SUBSET], shuffle=True)\n",
    "ds.create('val_unseen', val_pages[SUBSET])\n",
    "ds.create('val_seen', rng.choice(train_pages[SUBSET], SUBSET.stop or 200, replace=False))\n",
    "ds.get_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ name: set(p.site.name for p in items.pages) for name, items in ds.datasets.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.summarize_pages_without_visual_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.features = [\n",
    "    features.Depth(),\n",
    "    features.IsLeaf(),\n",
    "    features.CharCategories(),\n",
    "    features.Visuals(),\n",
    "    features.CharIdentifiers(),\n",
    "    features.WordIdentifiers()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.root.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to invalidate prepared features.\n",
    "#ds.delete_saved_root_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds.root.cutoff_words is None:\n",
    "    ds.root.cutoff_words = 15\n",
    "if ds.root.cutoff_word_length is None:\n",
    "    ds.root.cutoff_word_length = 10\n",
    "ds.root.extract_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_root = ds.root.describe()\n",
    "prev_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_features(parallelize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_root = ds.root.describe()\n",
    "curr_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.root.describe_visual_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.root.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_root_context(\n",
    "    overwrite_existing=(prev_root['pages'] != curr_root['pages'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to update shapes of previously-computed features.\n",
    "#ds.update_features(parallelize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to invalidate computed features.\n",
    "#ds.delete_saved_features(parallelize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.compute_features(parallelize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.first_dataset.label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.count_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create_dataloaders(batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ds['train'][i] for i in [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds['train'].loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# for batch in ds['train'].loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "interesting_nodes = (\n",
    "    (ctx.page.file_path, node, batch.x[idx], batch.y[idx])\n",
    "    for ctx, node, batch, idx in ds['val_seen'].iterate_data()\n",
    "    if node.labels == ['price']\n",
    ")\n",
    "iterator = itertools.islice(interesting_nodes, 0, None)\n",
    "next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.feature_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all labeled nodes also leaf nodes?\n",
    "from tqdm.auto import tqdm\n",
    "def verify_leaf_nodes(names):\n",
    "    for name in names:\n",
    "        for page in tqdm(ds[name].pages, desc=name):\n",
    "            ctx = ds.create_page_context(page)\n",
    "            for node in ctx.nodes:\n",
    "                if len(node.labels) != 0 and not node.is_text:\n",
    "                    print(f'Node {node.xpath} with labels {node.labels} in page {page.identifier} is not leaf.')\n",
    "                    return\n",
    "#verify_leaf_nodes(['train', 'val', 'unseen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many words were found in the pretrained GloVe embeddings.\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "stats = collections.defaultdict(int)\n",
    "if False:\n",
    "    for batch in tqdm(ds['train'].loader, desc='train'):\n",
    "        word_ids = extraction.collate(batch.word_identifiers)\n",
    "        for t in word_ids:\n",
    "            stats['unknown'] += sum(1 for x in t if x == 0)\n",
    "            stats['found'] += sum(1 for x in t if x >= 1)\n",
    "            stats['lens'] += len(t)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(data: list[data.Data], label: int):\n",
    "    return sum(1 for d in data for y in d.y if y == label)\n",
    "\n",
    "def count_labels(data: list[data.Data]):\n",
    "    return [count_label(data, label) for label in ds.first_dataset.label_map.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = []\n",
    "#label_counts = count_labels(ds['train'])\n",
    "{\n",
    "    label: count\n",
    "    for label, count in\n",
    "    zip(ds.first_dataset.label_map.keys(), label_counts)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_weights = [len(ds['train']) / count for count in label_counts]\n",
    "#label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual override\n",
    "label_count = len(ds.first_dataset.label_map)\n",
    "label_weights = [1] + [300] * (label_count - 1)\n",
    "label_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from awe import awe_model, gym, utils\n",
    "from awe.data import data_module\n",
    "from awe.features import extraction\n",
    "\n",
    "for module in [awe_model, gym, utils, data_module, extraction]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = awe_model.AweModel(\n",
    "    feature_count=ds.feature_dim,\n",
    "    label_count=label_count,\n",
    "    label_weights=label_weights,\n",
    "    char_count=len(ds.root.chars) + 1,\n",
    "    use_gnn=True,\n",
    "    use_lstm=True,\n",
    "    use_cnn=False,\n",
    "    lstm_args={\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        'bidirectional': True,\n",
    "        'num_layers': 2\n",
    "    },\n",
    "    filter_node_words=True,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "model, model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gym.Gym(ds, model)\n",
    "# Comment next line to restore previously trained model.\n",
    "g.restore_checkpoint = False\n",
    "g.get_last_checkpoint_path(), g.get_last_checkpoint_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer = pl.Trainer(\n",
    "    gpus=torch.cuda.device_count(),\n",
    "    max_epochs=50,\n",
    "    callbacks=[gym.CustomProgressBar(refresh_rate=10)],\n",
    "    resume_from_checkpoint=g.get_last_checkpoint_path(),\n",
    "    logger=g.create_logger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.logger.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_inputs()\n",
    "g.save_model_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.fit(model, data_module.DataModule(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Breaks torch_geometric for some reason!\n",
    "#g.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_results('val_unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_results('val_seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and change name to save interesting results.\n",
    "#g.save_named_version('29-lstm-2-layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awe import predictor\n",
    "\n",
    "for module in [predictor, awe_graph, awe_model]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on manually-selected pages.\n",
    "PREDICT_MANUAL = False\n",
    "if PREDICT_MANUAL:\n",
    "    ds.create('pred', sds.verticals[0].websites[0].pages[:4])\n",
    "    ds.compute_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ds = 'pred' if PREDICT_MANUAL else 'val_unseen'\n",
    "val_predictor = predictor.Predictor(ds, target_ds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_total = len(val_predictor.items)\n",
    "predict_indices = np.random.choice(predict_total, 4, replace=False)\n",
    "predict_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with awe_graph.HtmlPageCaching():\n",
    "    pred_metrics = val_predictor.evaluate(predict_indices)\n",
    "    pred_texts = val_predictor.get_example_texts(predict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://www.cars.com/vehicledetail/81d8ee1f-155e-44ec-8ea4-0b25b0ca608a/'\n",
    "]\n",
    "live_pages = [live.Page(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pages.\n",
    "[page.dom for page in live_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create('live', live_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.compute_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor = predictor.Predictor(ds, 'live', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor.get_example_texts(range(len(live_pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
