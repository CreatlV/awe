{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from typing import TypeVar\n",
    "\n",
    "import torch\n",
    "from torch_geometric import data, loader\n",
    "import numpy as np\n",
    "\n",
    "from awe import utils, filtering, features, html_utils, awe_graph, visual\n",
    "from awe.data import swde, live, dataset\n",
    "\n",
    "for module in [utils, filtering, dataset, swde, live, features, html_utils, awe_graph, visual]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = swde.Dataset(suffix='-exact')\n",
    "#sds.validate()\n",
    "ds = dataset.DatasetCollection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "def train_val_split(data: list[T], val_split: float):\n",
    "    split = int(np.floor(val_split * len(data)))\n",
    "    copy = list(data)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(copy)\n",
    "    return copy[split:], copy[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical = sds.verticals[0]\n",
    "#train_pages, val_pages = train_val_split(website.pages[:100], .2)\n",
    "train_pages = vertical.websites[0].pages[:300]\n",
    "val_pages = vertical.websites[0].pages[300:400]\n",
    "unseen_pages = vertical.websites[1].pages[:100]\n",
    "len(train_pages), len(val_pages), len(unseen_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.features = [\n",
    "    features.Depth(),\n",
    "    features.IsLeaf(),\n",
    "    features.CharCategories(),\n",
    "    features.FontSize(),\n",
    "    features.WordEmbedding(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.feature_dim, ds.feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create('train', train_pages)\n",
    "ds.create('val', val_pages)\n",
    "ds.create('unseen', unseen_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to invalidate computed features.\n",
    "#ds.delete_saved_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.parallelize = None\n",
    "ds['train'].prepare()\n",
    "ds['val'].prepare()\n",
    "ds['unseen'].prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.first_dataset.label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "ds['train'].loader = loader.DataLoader(ds['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "ds['val'].loader = loader.DataLoader(ds['val'], batch_size=BATCH_SIZE)\n",
    "ds['unseen'].loader = loader.DataLoader(ds['unseen'], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds['train'].loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds['train'].loader) + len(ds['val'].loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_nodes = (\n",
    "    (node, x, y)\n",
    "    for node, x, y in ds['val'].iterate_data()\n",
    "    if node.labels == ['price']\n",
    ")\n",
    "next(iter(interesting_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all labeled nodes also leaf nodes?\n",
    "from tqdm.auto import tqdm\n",
    "def verify_leaf_nodes(names):\n",
    "    for name in names:\n",
    "        for page in tqdm(ds[name].pages, desc=name):\n",
    "            ctx = ds.create_context(page)\n",
    "            for node in ctx.nodes:\n",
    "                if len(node.labels) != 0 and not node.is_text:\n",
    "                    print(f'Node {node.xpath} with labels {node.labels} in page {page.identifier} is not leaf.')\n",
    "                    return\n",
    "#verify_leaf_nodes(['train', 'val', 'unseen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(data: list[data.Data], label: int):\n",
    "    return len([1 for d in data for y in d.y if y == label])\n",
    "\n",
    "def count_labels(data: list[data.Data]):\n",
    "    return [count_label(data, label) for label in ds.first_dataset.label_map.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_counts = count_labels(ds['train'])\n",
    "#label_counts, len(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_weights = [len(ds['train']) / count for count in label_counts]\n",
    "#label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual override\n",
    "label_count = len(ds.first_dataset.label_map)\n",
    "label_weights = [1] + [100_000] * (label_count - 1)\n",
    "label_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from awe import awe_model, gym, utils\n",
    "for module in [awe_model, gym, utils]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = awe_model.AweModel(ds.feature_dim, label_count, label_weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gym.Gym(ds, model)\n",
    "# Uncomment next line to re-train a model.\n",
    "g.restore_checkpoint = False\n",
    "g.get_last_checkpoint_path(), g.get_last_checkpoint_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    callbacks=[gym.CustomProgressBar(refresh_rate=100)],\n",
    "    resume_from_checkpoint=g.get_last_checkpoint_path(),\n",
    "    logger=g.create_logger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.logger.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.fit(model, ds['train'].loader, ds['val'].loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Breaks torch_geometric for some reason!\n",
    "#g.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_model_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_results('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_results('unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and change name to save interesting results.\n",
    "#g.save_named_version('only-leaf-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awe import predictor\n",
    "importlib.reload(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor = predictor.Predictor(ds, 'unseen', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_total = len(val_predictor.items)\n",
    "predict_indices = [0, 1, predict_total - 2, predict_total - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor.evaluate(predict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor.get_example_texts(predict_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://www.cars.com/vehicledetail/81d8ee1f-155e-44ec-8ea4-0b25b0ca608a/'\n",
    "]\n",
    "live_pages = [live.Page(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pages.\n",
    "[page.dom for page in live_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create('live', live_pages).prepare(skip_existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor = predictor.Predictor(ds, 'live', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor.get_example_texts(range(len(live_pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
