{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch_geometric import data\n",
    "import numpy as np\n",
    "\n",
    "from awe import utils, filtering, features, extraction, html_utils, awe_graph, visual\n",
    "from awe.data import swde, live, dataset\n",
    "\n",
    "for module in [utils, filtering, dataset, swde, live, features, extraction, html_utils, awe_graph, visual]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = swde.Dataset(suffix='-exact')\n",
    "#sds.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = slice(2)\n",
    "vertical = sds.verticals[0]\n",
    "train_pages = vertical.websites[0].pages[:400] + vertical.websites[1].pages[:100] + vertical.websites[2].pages[:100]\n",
    "val_pages = vertical.websites[3].pages[:100]\n",
    "ds = dataset.DatasetCollection()\n",
    "ds.create('train', train_pages[SUBSET], shuffle=True)\n",
    "ds.create('val', val_pages[SUBSET])\n",
    "ds.get_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.summarize_pages_without_visual_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.features = [\n",
    "    features.Depth(),\n",
    "    features.IsLeaf(),\n",
    "    features.CharCategories(),\n",
    "    features.FontSize(),\n",
    "    features.CharIdentifiers(),\n",
    "    features.WordIdentifiers(),\n",
    "]\n",
    "ds.feature_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to invalidate prepared features.\n",
    "#ds.delete_saved_root_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.root.pages), len(ds.root.chars), len(ds.root.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find longest word.\n",
    "tokens = list(ds.root.tokens)\n",
    "word = tokens[np.argmax(list(map(len, tokens)))]\n",
    "word, len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_root_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line to invalidate computed features.\n",
    "#ds.delete_saved_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.compute_features(parallelize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.first_dataset.label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.count_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create_dataloaders(batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds['train'].loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_nodes = (\n",
    "    (node, x, y)\n",
    "    for node, x, y in ds['val'].iterate_data()\n",
    "    if node.labels == ['price']\n",
    ")\n",
    "next(iter(interesting_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all labeled nodes also leaf nodes?\n",
    "from tqdm.auto import tqdm\n",
    "def verify_leaf_nodes(names):\n",
    "    for name in names:\n",
    "        for page in tqdm(ds[name].pages, desc=name):\n",
    "            ctx = ds.create_page_context(page)\n",
    "            for node in ctx.nodes:\n",
    "                if len(node.labels) != 0 and not node.is_text:\n",
    "                    print(f'Node {node.xpath} with labels {node.labels} in page {page.identifier} is not leaf.')\n",
    "                    return\n",
    "#verify_leaf_nodes(['train', 'val', 'unseen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many words were found in the pretrained GloVe embeddings.\n",
    "import collections\n",
    "stats = collections.defaultdict(int)\n",
    "if False:\n",
    "    for batch in ds['train'].loader:\n",
    "        word_ids = extraction.collate(batch.word_identifiers)\n",
    "        for t in word_ids:\n",
    "            stats['pad'] += sum(1 for x in t if x == 0)\n",
    "            stats['unknown'] += sum(1 for x in t if x == 1)\n",
    "            stats['found'] += sum(1 for x in t if x >= 2)\n",
    "            stats['lens'] += len(t)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(data: list[data.Data], label: int):\n",
    "    return sum(1 for d in data for y in d.y if y == label)\n",
    "\n",
    "def count_labels(data: list[data.Data]):\n",
    "    return [count_label(data, label) for label in ds.first_dataset.label_map.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = []\n",
    "#label_counts = count_labels(ds['train'])\n",
    "{\n",
    "    label: count\n",
    "    for label, count in\n",
    "    zip(ds.first_dataset.label_map.keys(), label_counts)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_weights = [len(ds['train']) / count for count in label_counts]\n",
    "#label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual override\n",
    "label_count = len(ds.first_dataset.label_map)\n",
    "label_weights = [1] + [100_000] * (label_count - 1)\n",
    "label_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from awe import awe_model, gym, utils\n",
    "for module in [awe_model, gym, utils]:\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = awe_model.AweModel(\n",
    "    feature_count=ds.feature_dim,\n",
    "    label_count=label_count,\n",
    "    label_weights=label_weights,\n",
    "    char_count=len(ds.root.chars),\n",
    "    use_gnn=False)\n",
    "model, model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gym.Gym(ds, model)\n",
    "# Comment next line to restore previously trained model.\n",
    "g.restore_checkpoint = False\n",
    "g.get_last_checkpoint_path(), g.get_last_checkpoint_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[gym.CustomProgressBar(refresh_rate=100)],\n",
    "    resume_from_checkpoint=g.get_last_checkpoint_path(),\n",
    "    logger=g.create_logger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.logger.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.trainer.fit(model, ds['train'].loader, ds['val'].loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Breaks torch_geometric for some reason!\n",
    "#g.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_model_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_results('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and change name to save interesting results.\n",
    "#g.save_named_version('seed-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awe import predictor\n",
    "importlib.reload(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor = predictor.Predictor(ds, 'val', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_total = len(val_predictor.items)\n",
    "predict_indices = [0, 1, predict_total - 2, predict_total - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor.evaluate(predict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor.get_example_texts(predict_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://www.cars.com/vehicledetail/81d8ee1f-155e-44ec-8ea4-0b25b0ca608a/'\n",
    "]\n",
    "live_pages = [live.Page(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pages.\n",
    "[page.dom for page in live_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create('live', live_pages).prepare(skip_existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor = predictor.Predictor(ds, 'live', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_predictor.get_example_texts(range(len(live_pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
